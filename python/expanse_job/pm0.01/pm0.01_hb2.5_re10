#!/bin/bash
#SBATCH --job-name="Dedalus_KH" # Job name
#SBATCH --partition=compute # Switch to compute if you need 128 cores
#SBATCH --account=TG-PHY210050 # don't put this part on github!
#SBATCH --output="pm0.01_hb2.5_re10.o%j" # Name of stdout output file
#SBATCH --error="pm0.01_hb2.5_re10.e%j" # Name of stderr error file
#SBATCH --nodes=1 # Total number of nodes
#SBATCH --ntasks-per-node=64 # Total number of mpi tasks per node
#SBATCH --mem=128G # Memory per node; max 248G (in compute queue)
#SBATCH -t 06:00:00 # Run time (hh:mm:ss)

module load openmpi/4.0.4
module load python/3.8.5
module load py-six/1.14.0
module load py-mpi4py
module load py-h5py
module load py-numpy
module load py-scipy
module load fftw
module load py-pip

mpirun -n 64 python3 planar_Kolmogorov_2D_test.py config_files/pm0.01/pm0.01_hb2.5_re10
